{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa2af50060d9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from datasets import load_from_disk, Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import configs\n",
    "from controller.memory_manager import MemoryManager\n",
    "from data_processor.data_loader import GSM8KDataset\n",
    "from generator.crv_generator import CRVGenerator\n",
    "from generator.text_generator import TextGenerator\n",
    "\n",
    "from retrieve.cosine_similarity import CRVRetriever\n",
    "from retrieve.dnc import DNMemory\n",
    "from utils import set_seed, logger\n",
    "from utils import extract_test_cases, extract_functions, extract_sections, add_parsed_functions_to_dataset, CustomDataset\n",
    "\n",
    "from utils.loading_model import CustomTransformerLoader\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "# from rich import print\n",
    "from rich.console import Console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696654b1-279c-46ec-ac35-841112a788ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and console\n",
    "console = Console()\n",
    "logger = logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55dd0d2-6866-42bb-b9dc-02ab954746f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "model_urls = {\n",
    "    \"llama31\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"llama3\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "}\n",
    "model_path = model_urls[\"llama31\"]\n",
    "tokenizer_path = model_path\n",
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de6a1f3-a3fb-40a1-9d97-ce339294e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sg23454/PycharmProjects/moc/venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:961: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Loading the Model</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[92m──────────────────────────────────────────────── \u001B[0m\u001B[1;31mLoading the Model\u001B[0m\u001B[92m ────────────────────────────────────────────────\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_path, use_auth_token=hf_token)\n",
    "\n",
    "console.rule(\"[bold red]Loading the Model\")\n",
    "\n",
    "loader = CustomTransformerLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5913df29-187a-4fc9-b839-5beb932b7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sg23454/PycharmProjects/moc/venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/sg23454/PycharmProjects/moc/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3220: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3581c3a1c6c74f89903bcd24063514c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":warning: model type:  <class 'moc_layers.LlamaForCausalLM'>\n",
      "config.hidden_size:  32\n",
      "config._attn_implementation:  eager\n"
     ]
    }
   ],
   "source": [
    "# mp.set_start_method('spawn')\n",
    "model, tokenizer = loader.load_model(\n",
    "    model_path=model_path, tokenizer_path=tokenizer_path, hf_token=hf_token\n",
    ")\n",
    "\n",
    "crv_layers = configs.CRV_LAYERS\n",
    "\n",
    "print(\":warning: model type: \", type(model))\n",
    "print(\"config.hidden_size: \", config.num_hidden_layers)\n",
    "print(\"config._attn_implementation: \", config._attn_implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f01675-9f5c-4d04-8e47-9269d3474364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedLLaMACRVFramework:\n",
    "    def __init__(self, model, tokenizer, layer_idx = 10):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_generator = TextGenerator(model, tokenizer)\n",
    "        self.crv_generator = CRVGenerator(model, tokenizer, max_length=configs.MAX_LENGTH)\n",
    "        self.memory_manager = MemoryManager(model, max_memories=5)\n",
    "        self.layer_idx = layer_idx\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.text_generator = TextGenerator(model, tokenizer, device=self.device)\n",
    "\n",
    "    def generate_thought_trajectories(self, input_query, context=None, test_cases=None, max_new_tokens=1000, alt_text=None):\n",
    "        prompt_template = f\"\"\"\n",
    "        <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        Enable code_interpreter tool.<|eot_id|>\n",
    "        \\n\\n\n",
    "        {context if not context is None else alt_text}\n",
    "        \n",
    "        \\n\\n{input_query}.\n",
    "        \n",
    "        \\n\\nYour outputs must follow this structure and make sure you open and close the tags accurately:\n",
    "\n",
    "        Identify the core components of this problem.\n",
    "        1. Identify potential edge cases and tricky parts.\n",
    "        2. Write 2 short test cases for the edge cases and tricky parts.\n",
    "        \n",
    "        <chain_of_thoughts>\n",
    "        1. you must consider the edge cases according to the problem statement.\n",
    "        2. Begin with a <thinking> section.\n",
    "        3. Inside the thinking section:\n",
    "           a. Write the topic name of the query, the name of the algorithm if necessary.\n",
    "           b. Draft an answer as an expert.\n",
    "           b. Briefly analyze the question and outline your approach.\n",
    "           c. Present a clear plan of steps to solve the problem.\n",
    "           d. Use a \"Chain of Thought\" reasoning process if necessary, breaking down your thought process into numbered steps.\n",
    "        4. Include a <reflection> section for each idea where you:\n",
    "           a. Review your reasoning.\n",
    "           b. Check for potential errors or oversights.\n",
    "           c. Confirm or adjust your conclusion if necessary.\n",
    "        5. Be sure to close all reflection sections.\n",
    "        6. Close the thinking section with </thinking>.\n",
    "        7. Provide your final answer in an <output> section.        \n",
    "        </chain_of_thoughts>\n",
    "\n",
    "        <chain_of_thought_selection>\n",
    "        you must consider the edge cases according to the problem statement and select the most promising chain of thought that solves the edge cases (not necessarily the simplest nor the standard approach).\n",
    "        </chain_of_thought_selection>\n",
    "\n",
    "        <solution>\n",
    "        1. As a Python expert, generate the Python code and make sure it solves the edge cases while keeping it efficient.\n",
    "        2. the internal steps must produce the required output.\n",
    "        </solution>\n",
    "\n",
    "        Include a <reflection> section for the selected solution where if it is not correct, modify or if necessary, rewrite the solution and pay attention to the input problem.\n",
    "           a. Review your reasoning.\n",
    "           b. Check for potential errors or oversights according to the problem. you must consider the edge cases according to the problem. Make sure it is not overcomplicated.\n",
    "           c. Confirm or adjust your conclusion if necessary.\n",
    "        4. Be sure to close all reflection sections.\n",
    "        \n",
    "        <context_generation>\n",
    "        1. Rewrite the problem.\n",
    "        2. Rewrite the edge cases and tricky parts in one short sentence\n",
    "        2. Generate a very accurate and minimal Python code/pseudocode for the final solution. Ensure that the final solution is minimal and accurate.\n",
    "        </context_generation>\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        \"\"\"\n",
    "\n",
    "        generated_text = self.text_generator.generate_text(\n",
    "            prompt_template,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences = 1,\n",
    "            output_file=\"data/results.csv\",\n",
    "            # stop_sequences=[\"The end\", \".\\n\\n\"],\n",
    "        )\n",
    "        # print(\"generated_thought trajectory: \", generated_text)\n",
    "\n",
    "        return generated_text\n",
    "    \n",
    "    def extract_hidden_states(self, context):\n",
    "        best_crv, seq_length = self.crv_generator.generate_crvs(\n",
    "            context, crv_layers=crv_layers, max_length=configs.MAX_LENGTH\n",
    "        )\n",
    "        return best_crv, seq_length  # Return the hidden state and its len\n",
    "\n",
    "    def generate_crv(self, hidden_states, seq_length):\n",
    "        # return torch.mean(hidden_states, dim=1)\n",
    "        return hidden_states, seq_length\n",
    "        \n",
    "    def final_generation(self, original_query, test_cases, crv, seq_length, max_new_tokens=250):\n",
    "\n",
    "        query=f\"\"\"<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\n{original_query}.\\nYour code should pass the following tests:{test_cases}\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\"\"\"\n",
    "        # Combine original query and CRV\n",
    "        self.memory_manager.add_memory(\n",
    "        crv, seq_length, layer_idx=self.layer_idx, crv_layers=crv_layers\n",
    "    )\n",
    "\n",
    "        # model.model.set_post_concat_crv(True)\n",
    "        self.memory_manager.set_concat_positions(0, start_pos=0, end_pos=seq_length)\n",
    "        if isinstance(self.layer_idx, int):\n",
    "            self.memory_manager.apply_memory_to_model(0)\n",
    "        generated_text = self.text_generator.generate_text(\n",
    "            query,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences = 1,\n",
    "            output_file=\"data/results.csv\",\n",
    "            # stop_sequences=[\"The end\", \".\\n\\n\"],\n",
    "        )\n",
    "        return generated_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f10ce6-8cea-4da8-b689-8d68acffe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_text = '''<|start_header_id|>user<|end_header_id|>You are an expert Python programmer designed to provide standard, accurate,and fully working codes, and here is your task:\\n\n",
    "        \\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n res = tuple(set(test_tup1) & set(test_tup2))\\n return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n result = False\\n for i in range(2,int(math.sqrt(n)) + 1):\\n if n % i == 0:\\n result = True\\n return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n largest_nums = hq.nlargest(n, nums)\\n return largest_nums\\n```<|eot_id|>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc304549-af46-4f55-8b9f-20b6f63edf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():    \n",
    "    # Print column names\n",
    "    print(\"\\nColumns in the updated dataset:\")\n",
    "    print(updated_dataset.column_names)\n",
    "    # loaded_dataset2 = load_from_disk(\"data/processed_meta_llama_dataset_with_results\")\n",
    "    loaded_dataset2 = load_dataset(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct-evals\",\n",
    "    name=\"Meta-Llama-3.1-8B-Instruct-evals__mbpp__details\",\n",
    "    split=\"latest\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Print selected columns from the first 5 rows of the updated dataset\n",
    "    print(\"First 5 rows of the updated dataset (selected columns):\")\n",
    "    for i, example in enumerate(loaded_dataset2.select(range(num_examples))):\n",
    "        print(f\"\\nExample {i + 1}:\")\n",
    "        # Print original columns\n",
    "        print(f\"input_correct_responses: {example['input_correct_responses']}...\")\n",
    "        # print(f\"extracted_functions_layer_15: {example['extracted_functions_layer_15']}...\")\n",
    "        \n",
    "        # Print new columns for each layer\n",
    "        for layer in layer_indices:\n",
    "            print(f\"\\nLayer {layer}:\")\n",
    "            final_output = example.get(f'final_output_layer_{layer}')\n",
    "            extracted_functions = example.get(f'extracted_functions_layer_{layer}')\n",
    "            \n",
    "            if final_output:\n",
    "                print(f\"Final Output: {final_output[:100]}...\")\n",
    "            else:\n",
    "                print(\"Final Output: None\")\n",
    "            \n",
    "            if extracted_functions:\n",
    "                print(f\"Extracted Functions: {extracted_functions[:100]}...\")\n",
    "            else:\n",
    "                print(\"Extracted Functions: None\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3ff791-3d11-4830-b45b-9fd96cea0527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\e'\n",
      "/tmp/ipykernel_4054477/4074369213.py:19: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  print(\"\\end of context ----\")\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, tokenizer, dataset: Dataset, layer_indices: List[int], num_examples: int = -1) -> pd.DataFrame:\n",
    "    results = []\n",
    "    \n",
    "    for layer_idx in tqdm(layer_indices, desc=\"Processing layer indices\"):\n",
    "        framework = AdvancedLLaMACRVFramework(model, tokenizer, layer_idx=layer_idx)\n",
    "        \n",
    "        for i, instance in enumerate(tqdm(dataset, desc=f\"Processing instances for layer {layer_idx}\")):\n",
    "            if num_examples != -1 and i >= num_examples:\n",
    "                break\n",
    "            # print('instance: ', instance)\n",
    "            query = instance['query'][0] if instance['query'] else ''\n",
    "            context = instance['context'][0] if instance['context'] else '' \n",
    "            test_cases = '\\n'.join(extract_test_cases(instance['input_final_prompts'][0])[-1])\n",
    "            tmp = \"Proposed solution context: \"\n",
    "            trajectories_and_context = framework.generate_thought_trajectories(query, context, test_cases, max_new_tokens=1000, alt_text=alt_text)\n",
    "            context_expansion = extract_sections(trajectories_and_context, \"context_generation\")\n",
    "            context_expansion = tmp + context_expansion + extract_sections(trajectories_and_context, \"solution\")\n",
    "            # print('context_expansion: ', context_expansion)\n",
    "            # print(\"\\end of context ----\")\n",
    "            hidden_states, seq_len = framework.extract_hidden_states(context_expansion)\n",
    "            crv, seq_len = framework.generate_crv(hidden_states, seq_len)\n",
    "            \n",
    "            final_output = framework.final_generation(query, test_cases, crv, seq_len, max_new_tokens=250)\n",
    "            # print(\"final output: \", final_output)\n",
    "            extracted_functions = extract_functions(final_output)\n",
    "            \n",
    "            result = {\n",
    "                'layer_idx': layer_idx,\n",
    "                'instance_id': i,  # This should be the index in the dataset\n",
    "                'query': query,\n",
    "                'context': context,\n",
    "                'test_cases': test_cases,\n",
    "                'final_output': final_output,\n",
    "                'extracted_functions': extracted_functions\n",
    "            }\n",
    "            print(f'result {i}: ', result)\n",
    "            results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86716f98-f9ae-4a0d-bfe6-90aa7e6acebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing layer indices:   0%|                           | 0/2 [00:00<?, ?it/s]\n",
      "Processing instances for layer 15:   0%|                | 0/500 [00:00<?, ?it/s]\u001B[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Both `max_new_tokens` (=1000) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cases len:  4\n",
      " Here's the Python solution for the given problem:\n",
      "\n",
      "```python\n",
      "def check_distinct(tup):\n",
      "  return len(set(tup)) == len(tup)\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. The problem requires us to check if a given tuple is distinct or not.\n",
      "2. A distinct tuple has no duplicate elements.\n",
      "3. We can use Python's built-in set data type to remove duplicates from a tuple.\n",
      "4. If the length of the original tuple is equal to the length of the set created from the tuple, then the tuple is distinct.\n",
      "\n",
      "Edge Cases:\n",
      "\n",
      "- Test case 1: (1, 4, 5, 6, 1, 4)\n",
      "- Test case 2: (1, 4, 5, 6)\n",
      "- Test case 3: (2, 3, 4, 5, 6)\n",
      "\n",
      "The provided code will pass all these test cases as it correctly identifies distinct tuples.\n",
      "\n",
      "Note: Python tuples are inherently unordered, so it's not possible to have duplicate elements in a tuple in the classical sense. However, if you're working with a list and want to convert it to a tuple, you can use the tuple() function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.utils:The input received is a query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_thought trajectory:   Here's the Python solution for the given problem:\n",
      "\n",
      "```python\n",
      "def check_distinct(tup):\n",
      "  return len(set(tup)) == len(tup)\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. The problem requires us to check if a given tuple is distinct or not.\n",
      "2. A distinct tuple has no duplicate elements.\n",
      "3. We can use Python's built-in set data type to remove duplicates from a tuple.\n",
      "4. If the length of the original tuple is equal to the length of the set created from the tuple, then the tuple is distinct.\n",
      "\n",
      "Edge Cases:\n",
      "\n",
      "- Test case 1: (1, 4, 5, 6, 1, 4)\n",
      "- Test case 2: (1, 4, 5, 6)\n",
      "- Test case 3: (2, 3, 4, 5, 6)\n",
      "\n",
      "The provided code will pass all these test cases as it correctly identifies distinct tuples.\n",
      "\n",
      "Note: Python tuples are inherently unordered, so it's not possible to have duplicate elements in a tuple in the classical sense. However, if you're working with a list and want to convert it to a tuple, you can use the tuple() function.\n",
      "context_expansion:  Proposed solution context: def check_distinct(tup):\n",
      "  return len(set(tup)) == len(tup)\n",
      "```\n",
      "Explanation:\n",
      "1. The problem requires us to check if a given tuple is distinct or not.\n",
      "2. A distinct tuple has no duplicate elements.\n",
      "3. We can use Python's built-in set data type to remove duplicates from a tuple.\n",
      "4. If the length of the original tuple is equal to the length of the set created from the tuple, then the tuple is distinct.\n",
      "Edge Cases:\n",
      "- Test case 1: (1, 4, 5, 6, 1, 4)\n",
      "- Test case 2: (1, 4, 5, 6)\n",
      "- Test case 3: (2, 3, 4, 5, 6)\n",
      "The provided code will pass all these test cases as it correctly identifies distinct tuples.\n",
      "Note: Python tuples are inherently unordered, so it's not possible to have duplicate elements in a tuple in the classical sense. However, if you're working with a list and want to convert it to a tuple, you can use the tuple() function.def check_distinct(tup):\n",
      "  return len(set(tup)) == len(tup)\n",
      "```\n",
      "Explanation:\n",
      "1. The problem requires us to check if a given tuple is distinct or not.\n",
      "2. A distinct tuple has no duplicate elements.\n",
      "3. We can use Python's built-in set data type to remove duplicates from a tuple.\n",
      "4. If the length of the original tuple is equal to the length of the set created from the tuple, then the tuple is distinct.\n",
      "Edge Cases:\n",
      "- Test case 1: (1, 4, 5, 6, 1, 4)\n",
      "- Test case 2: (1, 4, 5, 6)\n",
      "- Test case 3: (2, 3, 4, 5, 6)\n",
      "The provided code will pass all these test cases as it correctly identifies distinct tuples.\n",
      "Note: Python tuples are inherently unordered, so it's not possible to have duplicate elements in a tuple in the classical sense. However, if you're working with a list and want to convert it to a tuple, you can use the tuple() function.\n",
      "\\end of context ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.utils:We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "INFO:controller.memory_manager:Added new memory. Current number of memories: 1\n",
      "INFO:controller.memory_manager:Set concat positions for memory 0: start=0, end=tensor([128], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Set CRV with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span> at layer <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Set CRV with shape \u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m6\u001B[0m, \u001B[1;36m128\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m at layer \u001B[1;36m15\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CRV layers: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "CRV layers: \u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m5\u001B[0m, \u001B[1;36m10\u001B[0m, \u001B[1;36m15\u001B[0m, \u001B[1;36m20\u001B[0m, \u001B[1;36m32\u001B[0m\u001B[1m]\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Concat positions: <span style=\"color: #808000; text-decoration-color: #808000\">start</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">end</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Concat positions: \u001B[33mstart\u001B[0m=\u001B[1;36m0\u001B[0m, \u001B[33mend\u001B[0m=\u001B[1;35mtensor\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1m]\u001B[0m, \u001B[33mdevice\u001B[0m=\u001B[32m'cuda:0'\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:controller.memory_manager:Applied memory 0 to model\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Both `max_new_tokens` (=250) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape of the new layer_crv: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "shape of the new layer_crv: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m128\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cat al layers <span style=\"font-weight: bold\">(</span>saved layers idx, and model idx<span style=\"font-weight: bold\">)</span>:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cat al layers \u001B[1m(\u001B[0msaved layers idx, and model idx\u001B[1m)\u001B[0m:  \u001B[1;36m3\u001B[0m \u001B[1;36m15\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden states before cat at layer <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">210</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden states before cat at layer \u001B[1;36m15\u001B[0m: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m210\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden states after cat: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">338</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden states after cat: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m338\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.utils:The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def check_distinct(tup):\n",
      "    \"\"\"\n",
      "    This function checks if all elements in a given tuple are distinct.\n",
      "    \n",
      "    Args:\n",
      "    tup (tuple): The input tuple to be checked.\n",
      "    \n",
      "    Returns:\n",
      "    bool: True if all elements in the tuple are distinct, False otherwise.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Convert the tuple to a set. A set in Python is an unordered collection of unique elements.\n",
      "    # If the lengths of the tuple and the set are not equal, then there were duplicates in the tuple.\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing instances for layer 15:   0%|      | 1/500 [00:24<3:24:07, 24.54s/it]\u001B[A\n",
      "Processing layer indices:  50%|█████████▌         | 1/2 [00:24<00:24, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output:  \n",
      "def check_distinct(tup):\n",
      "    \"\"\"\n",
      "    This function checks if all elements in a given tuple are distinct.\n",
      "    \n",
      "    Args:\n",
      "    tup (tuple): The input tuple to be checked.\n",
      "    \n",
      "    Returns:\n",
      "    bool: True if all elements in the tuple are distinct, False otherwise.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Convert the tuple to a set. A set in Python is an unordered collection of unique elements.\n",
      "    # If the lengths of the tuple and the set are not equal, then there were duplicates in the tuple.\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "result 0:  {'layer_idx': 15, 'instance_id': 0, 'query': '<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to check if given tuple is distinct or not.\\nYour code should pass the following tests:\\nassert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python', 'context': '<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|>', 'test_cases': 'assert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True', 'final_output': '\\ndef check_distinct(tup):\\n    \"\"\"\\n    This function checks if all elements in a given tuple are distinct.\\n    \\n    Args:\\n    tup (tuple): The input tuple to be checked.\\n    \\n    Returns:\\n    bool: True if all elements in the tuple are distinct, False otherwise.\\n    \"\"\"\\n    \\n    # Convert the tuple to a set. A set in Python is an unordered collection of unique elements.\\n    # If the lengths of the tuple and the set are not equal, then there were duplicates in the tuple.\\n    return len(tup) == len(set(tup))\\n```', 'extracted_functions': 'def check_distinct(tup):\\n    return len(tup) == len(set(tup))\\n```'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing instances for layer 20:   0%|                | 0/500 [00:00<?, ?it/s]\u001B[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Both `max_new_tokens` (=1000) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cases len:  4\n",
      " The final answer is:\n",
      "\n",
      "def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.utils:The input received is a query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_thought trajectory:   The final answer is:\n",
      "\n",
      "def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "\"\n",
      "context_expansion:  Proposed solution context: def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "\"def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "\"\n",
      "\\end of context ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:controller.memory_manager:Added new memory. Current number of memories: 1\n",
      "INFO:controller.memory_manager:Set concat positions for memory 0: start=0, end=tensor([46], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Set CRV with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span> at layer <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Set CRV with shape \u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m6\u001B[0m, \u001B[1;36m46\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m at layer \u001B[1;36m20\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CRV layers: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "CRV layers: \u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m5\u001B[0m, \u001B[1;36m10\u001B[0m, \u001B[1;36m15\u001B[0m, \u001B[1;36m20\u001B[0m, \u001B[1;36m32\u001B[0m\u001B[1m]\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Concat positions: <span style=\"color: #808000; text-decoration-color: #808000\">start</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">end</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Concat positions: \u001B[33mstart\u001B[0m=\u001B[1;36m0\u001B[0m, \u001B[33mend\u001B[0m=\u001B[1;35mtensor\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m46\u001B[0m\u001B[1m]\u001B[0m, \u001B[33mdevice\u001B[0m=\u001B[32m'cuda:0'\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:controller.memory_manager:Applied memory 0 to model\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Both `max_new_tokens` (=250) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape of the new layer_crv: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "shape of the new layer_crv: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m46\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cat al layers <span style=\"font-weight: bold\">(</span>saved layers idx, and model idx<span style=\"font-weight: bold\">)</span>:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cat al layers \u001B[1m(\u001B[0msaved layers idx, and model idx\u001B[1m)\u001B[0m:  \u001B[1;36m4\u001B[0m \u001B[1;36m20\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden states before cat at layer <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">210</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden states before cat at layer \u001B[1;36m20\u001B[0m: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m210\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden states after cat: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden states after cat: \n",
       "\u001B[1;35mtorch.Size\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m\u001B[1;36m1\u001B[0m, \u001B[1;36m256\u001B[0m, \u001B[1;36m4096\u001B[0m\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing instances for layer 20:   0%|        | 1/500 [00:05<45:05,  5.42s/it]\u001B[A\n",
      "Processing layer indices: 100%|███████████████████| 2/2 [00:29<00:00, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output:  \n",
      "def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "result 0:  {'layer_idx': 20, 'instance_id': 0, 'query': '<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to check if given tuple is distinct or not.\\nYour code should pass the following tests:\\nassert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python', 'context': '<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|>', 'test_cases': 'assert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True', 'final_output': '\\ndef check_distinct(tup):\\n    return len(tup) == len(set(tup))\\n```', 'extracted_functions': 'def check_distinct(tup):\\n    return len(tup) == len(set(tup))\\n```'}\n",
      "Type of updated_dataset: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Number of rows in updated_dataset: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c410a0bdecb04b9cb6a975df617d06a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_dataset = load_from_disk(\"data/processed_Meta-Llama-3.1-8B-Instruct-evals__mbpp__details\")\n",
    "\n",
    "# Define layer indices to evaluate\n",
    "layer_indices = [1, 10, 15, 20, 32, 'orig']\n",
    "num_examples=1\n",
    "# Evaluate model\n",
    "results_df = evaluate_model(model, tokenizer, loaded_dataset, layer_indices, num_examples=num_examples)\n",
    "\n",
    "# Add parsed functions to the dataset\n",
    "updated_dataset = add_parsed_functions_to_dataset(loaded_dataset, results_df, layer_indices)\n",
    "\n",
    "print(f\"Type of updated_dataset: {type(updated_dataset)}\")\n",
    "print(f\"Number of rows in updated_dataset: {len(updated_dataset)}\")\n",
    "\n",
    "\n",
    "# Save the updated dataset\n",
    "updated_dataset.save_to_disk(\"data/processed_meta_llama_dataset_with_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60e384e-9f0d-46a9-b3da-17e344ff6202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 2 rows of the dataset:\n",
      "Row 1:\n",
      "  task_type: Generative\n",
      "  task_name: mbpp_chat\n",
      "  subtask_name: None\n",
      "  input_question: Write a function to check if given tuple is distinct or not.\n",
      "  input_choice_list: None\n",
      "  input_final_prompts: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to check if given tuple is distinct or not.\\nYour code should pass the following tests:\\nassert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python']\n",
      "  input_correct_responses: None\n",
      "  output_prediction_text: ['\\ndef check_distinct(tup):\\n  return len(tup) == len(set(tup))\\n```']\n",
      "  output_parsed_answer: \n",
      "def check_distinct(tup):\n",
      "  return len(tup) == len(set(tup))\n",
      "\n",
      "  output_choice_completions: None\n",
      "  output_choice_negative_log_likelihoods: None\n",
      "  output_metrics: {'compiles@1': 1.0, 'pass@1': 1.0}\n",
      "  is_correct: True\n",
      "  input_question_hash: 5f95e606207366d0b090735637ee25085e3a99edfc4272637bfa3816b4743eb3\n",
      "  input_final_prompts_hash: ['9c7412dfa641dda248586db1638287547113760c3daa78ca2bc27cebfb3535be']\n",
      "  benchmark_label: MBPP\n",
      "  eval_config: {'max_gen_len': '256', 'max_prompt_len': '4500', 'num_few_shot': '3', 'num_generations': '1', 'prompt_fn': \"functools.partial(<function jinja_dialog_format at 0x7faafad1c790>, template={'prompt': 'You are an expert Python programmer, and here is your task:\\\\n{{ text }}\\\\nYour code should pass the following tests:\\\\n{{ prompt_tests }}', 'answer': '\\\\n```python\\\\n{{ code }}\\\\n```\\\\n', 'gen_prefix': '\\\\n```python\\\\n'}, append_gen_prefix=True)\", 'return_logprobs': 'false', 'seed': '42', 'temperature': '0.0', 'top_k': '0', 'top_p': '0'}\n",
      "  context: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|>']\n",
      "  query: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to check if given tuple is distinct or not.\\nYour code should pass the following tests:\\nassert check_distinct((1, 4, 5, 6, 1, 4)) == False\\nassert check_distinct((1, 4, 5, 6)) == True\\nassert check_distinct((2, 3, 4, 5, 6)) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python']\n",
      "  final_output_layer_15: \n",
      "def check_distinct(tup):\n",
      "    \"\"\"\n",
      "    This function checks if all elements in a given tuple are distinct.\n",
      "    \n",
      "    Args:\n",
      "    tup (tuple): The input tuple to be checked.\n",
      "    \n",
      "    Returns:\n",
      "    bool: True if all elements in the tuple are distinct, False otherwise.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Convert the tuple to a set. A set in Python is an unordered collection of unique elements.\n",
      "    # If the lengths of the tuple and the set are not equal, then there were duplicates in the tuple.\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "  final_output_layer_20: \n",
      "def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "  extracted_functions_layer_15: def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "  extracted_functions_layer_20: def check_distinct(tup):\n",
      "    return len(tup) == len(set(tup))\n",
      "```\n",
      "\n",
      "Row 2:\n",
      "  task_type: Generative\n",
      "  task_name: mbpp_chat\n",
      "  subtask_name: None\n",
      "  input_question: Write a python function to find the first non-repeated character in a given string.\n",
      "  input_choice_list: None\n",
      "  input_final_prompts: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to find the first non-repeated character in a given string.\\nYour code should pass the following tests:\\nassert first_non_repeating_character(\"abcabc\") == None\\nassert first_non_repeating_character(\"abc\") == \"a\"\\nassert first_non_repeating_character(\"ababc\") == \"c\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python']\n",
      "  input_correct_responses: None\n",
      "  output_prediction_text: ['\\ndef first_non_repeating_character(s):\\n    char_count = {}\\n    for char in s:\\n        if char in char_count:\\n            char_count[char] += 1\\n        else:\\n            char_count[char] = 1\\n    for char in s:\\n        if char_count[char] == 1:\\n            return char\\n    return None\\n```']\n",
      "  output_parsed_answer: \n",
      "def first_non_repeating_character(s):\n",
      "    char_count = {}\n",
      "    for char in s:\n",
      "        if char in char_count:\n",
      "            char_count[char] += 1\n",
      "        else:\n",
      "            char_count[char] = 1\n",
      "    for char in s:\n",
      "        if char_count[char] == 1:\n",
      "            return char\n",
      "    return None\n",
      "\n",
      "  output_choice_completions: None\n",
      "  output_choice_negative_log_likelihoods: None\n",
      "  output_metrics: {'compiles@1': 1.0, 'pass@1': 1.0}\n",
      "  is_correct: True\n",
      "  input_question_hash: cc38386cf8143ac55c409cb458e395d2bb9490e34923c25d5f2fbae489722a5d\n",
      "  input_final_prompts_hash: ['8a2ac8861b126e3cfa6d32d3430fc32c03495fda8f55ec816a11fbba9cad7dfb']\n",
      "  benchmark_label: MBPP\n",
      "  eval_config: {'max_gen_len': '256', 'max_prompt_len': '4500', 'num_few_shot': '3', 'num_generations': '1', 'prompt_fn': \"functools.partial(<function jinja_dialog_format at 0x7faafad1c790>, template={'prompt': 'You are an expert Python programmer, and here is your task:\\\\n{{ text }}\\\\nYour code should pass the following tests:\\\\n{{ prompt_tests }}', 'answer': '\\\\n```python\\\\n{{ code }}\\\\n```\\\\n', 'gen_prefix': '\\\\n```python\\\\n'}, append_gen_prefix=True)\", 'return_logprobs': 'false', 'seed': '42', 'temperature': '0.0', 'top_k': '0', 'top_p': '0'}\n",
      "  context: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the similar elements from the given two tuple lists.\\nYour code should pass the following tests:\\nassert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)\\nassert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)\\nassert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\ndef similar_elements(test_tup1, test_tup2):\\n  res = tuple(set(test_tup1) & set(test_tup2))\\n  return (res) \\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to identify non-prime numbers.\\nYour code should pass the following tests:\\nassert is_not_prime(2) == False\\nassert is_not_prime(10) == True\\nassert is_not_prime(35) == True<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport math\\ndef is_not_prime(n):\\n    result = False\\n    for i in range(2,int(math.sqrt(n)) + 1):\\n        if n % i == 0:\\n            result = True\\n    return result\\n```<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a function to find the largest integers from a given list of numbers using heap queue algorithm.\\nYour code should pass the following tests:\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75] \\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python\\nimport heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums\\n```<|eot_id|>']\n",
      "  query: ['<|start_header_id|>user<|end_header_id|>\\n\\nYou are an expert Python programmer, and here is your task:\\nWrite a python function to find the first non-repeated character in a given string.\\nYour code should pass the following tests:\\nassert first_non_repeating_character(\"abcabc\") == None\\nassert first_non_repeating_character(\"abc\") == \"a\"\\nassert first_non_repeating_character(\"ababc\") == \"c\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n```python']\n",
      "  final_output_layer_15: None\n",
      "  final_output_layer_20: None\n",
      "  extracted_functions_layer_15: None\n",
      "  extracted_functions_layer_20: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 2 rows of the dataset:\")\n",
    "for i, example in enumerate(updated_dataset):\n",
    "    if i < 2:\n",
    "        print(f\"Row {i + 1}:\")\n",
    "        for key, value in example.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()  # Add a blank line between rows\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ee130-7498-4889-a337-2f6d119fc84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
