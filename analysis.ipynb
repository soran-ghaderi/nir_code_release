{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdf8500-f6cf-491a-ad71-7a2c0da0d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_from_disk\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Callable\n",
    "from radon.metrics import h_visit\n",
    "from radon.complexity import cc_visit\n",
    "\n",
    "layer_indices = [1, 10, 23, 'orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"processed_Meta-Llama-3.1-8B-Instruct-evals__mbpp__details_results\"\n",
    "\n",
    "# dataset = load_from_disk(f\"data/{subset_name}\")\n",
    "df = pd.read_csv(\"checkpoints/latest_results_clone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd786af8-7260-497c-97e8-0eaf307189a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_name</th>\n",
       "      <th>subtask_name</th>\n",
       "      <th>input_question</th>\n",
       "      <th>input_choice_list</th>\n",
       "      <th>input_final_prompts</th>\n",
       "      <th>input_correct_responses</th>\n",
       "      <th>output_prediction_text</th>\n",
       "      <th>output_parsed_answer</th>\n",
       "      <th>output_choice_completions</th>\n",
       "      <th>...</th>\n",
       "      <th>trajectories_and_context_10</th>\n",
       "      <th>context_expansion_10</th>\n",
       "      <th>final_output_23</th>\n",
       "      <th>extracted_functions_23</th>\n",
       "      <th>trajectories_and_context_23</th>\n",
       "      <th>context_expansion_23</th>\n",
       "      <th>final_output_orig</th>\n",
       "      <th>extracted_functions_orig</th>\n",
       "      <th>trajectories_and_context_orig</th>\n",
       "      <th>context_expansion_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mbpp_chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a function to check if given tuple is di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\ndef check_distinct(tup):\\n  return len(tup...</td>\n",
       "      <td>\\ndef check_distinct(tup):\\n  return len(tup) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n        &lt;thinking&gt;\\n    ...</td>\n",
       "      <td>Proposed solution context: Given a tuple, chec...</td>\n",
       "      <td>\\ndef check_distinct(numbers):\\n    \"\"\"Check i...</td>\n",
       "      <td>def check_distinct(numbers):\\n    return len(n...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Write a fu...</td>\n",
       "      <td>\\ndef check_distinct(numbers):\\n    \"\"\"\\n    C...</td>\n",
       "      <td>def check_distinct(numbers):\\n    return len(n...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n    &lt;top...</td>\n",
       "      <td>Proposed solution context: Problem: Check if a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mbpp_chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a python function to find the first non-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\ndef first_non_repeating_character(s):\\n   ...</td>\n",
       "      <td>\\ndef first_non_repeating_character(s):\\n    c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n        &lt;thinking&gt;\\n    ...</td>\n",
       "      <td>Proposed solution context: def first_non_repea...</td>\n",
       "      <td>\\ndef first_non_repeating_character(s):\\n    c...</td>\n",
       "      <td>def first_non_repeating_character(s):\\n    cha...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: The problem is to f...</td>\n",
       "      <td>\\ndef first_non_repeating_character(s):\\n    \"...</td>\n",
       "      <td>def first_non_repeating_character(s):\\n    cha...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n        &lt;thinking&gt;\\n    ...</td>\n",
       "      <td>Proposed solution context: The problem is to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mbpp_chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a function to check whether the given st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\nimport re\\ndef check_char(s):\\n    if re.m...</td>\n",
       "      <td>\\nimport re\\ndef check_char(s):\\n    if re.mat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n        &lt;thinking&gt;\\n    ...</td>\n",
       "      <td>Proposed solution context: Problem: Check if a...</td>\n",
       "      <td>\\ndef check_char(s):\\n    \"\"\"Returns 'Valid' i...</td>\n",
       "      <td>def check_char(s):\\n    if len(set(s)) == 1:\\n...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: def check_char(s):\\...</td>\n",
       "      <td>\\ndef check_char(s):\\n    \"\"\"\\n    This functi...</td>\n",
       "      <td>def check_char(s):\\n    s = s.lower()\\n    if ...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: The problem stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mbpp_chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a function to perform index wise additio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\ndef add_nested_tuples(tup1, tup2):\\n  retu...</td>\n",
       "      <td>\\ndef add_nested_tuples(tup1, tup2):\\n  return...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Write a fu...</td>\n",
       "      <td>\\ndef add_nested_tuples(tup1, tup2):\\n    if l...</td>\n",
       "      <td>def add_nested_tuples(tup1, tup2):\\n    if len...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Write a fu...</td>\n",
       "      <td>\\ndef add_nested_tuples(tup1, tup2):\\n    \"\"\"\\...</td>\n",
       "      <td>def add_nested_tuples(tup1, tup2):\\n    return...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Write a fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mbpp_chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a function to compute the value of ncr%p.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['\\ndef ncr_modp(n, r, p):\\n    if n &lt; r:\\n   ...</td>\n",
       "      <td>\\ndef ncr_modp(n, r, p):\\n    if n &lt; r:\\n     ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Calculate ...</td>\n",
       "      <td>\\nimport math\\n\\ndef ncr_modp(n, r, p):\\n    i...</td>\n",
       "      <td>import math\\n\\ndef ncr_modp(n, r, p):\\n    if ...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Calculate ...</td>\n",
       "      <td>\\ndef ncr_modp(n, r, p):\\n    if r &gt; n - r: \\n...</td>\n",
       "      <td>def ncr_modp(n, r, p):\\n    if r &gt; n - r: \\n  ...</td>\n",
       "      <td>&lt;chain_of_thoughts&gt;\\n    &lt;thinking&gt;\\n        ...</td>\n",
       "      <td>Proposed solution context: Problem: Calculate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_type  task_name  subtask_name  \\\n",
       "0  Generative  mbpp_chat           NaN   \n",
       "1  Generative  mbpp_chat           NaN   \n",
       "2  Generative  mbpp_chat           NaN   \n",
       "3  Generative  mbpp_chat           NaN   \n",
       "4  Generative  mbpp_chat           NaN   \n",
       "\n",
       "                                      input_question  input_choice_list  \\\n",
       "0  Write a function to check if given tuple is di...                NaN   \n",
       "1  Write a python function to find the first non-...                NaN   \n",
       "2  Write a function to check whether the given st...                NaN   \n",
       "3  Write a function to perform index wise additio...                NaN   \n",
       "4    Write a function to compute the value of ncr%p.                NaN   \n",
       "\n",
       "                                 input_final_prompts  input_correct_responses  \\\n",
       "0  ['<|start_header_id|>user<|end_header_id|>\\n\\n...                      NaN   \n",
       "1  ['<|start_header_id|>user<|end_header_id|>\\n\\n...                      NaN   \n",
       "2  ['<|start_header_id|>user<|end_header_id|>\\n\\n...                      NaN   \n",
       "3  ['<|start_header_id|>user<|end_header_id|>\\n\\n...                      NaN   \n",
       "4  ['<|start_header_id|>user<|end_header_id|>\\n\\n...                      NaN   \n",
       "\n",
       "                              output_prediction_text  \\\n",
       "0  ['\\ndef check_distinct(tup):\\n  return len(tup...   \n",
       "1  ['\\ndef first_non_repeating_character(s):\\n   ...   \n",
       "2  ['\\nimport re\\ndef check_char(s):\\n    if re.m...   \n",
       "3  ['\\ndef add_nested_tuples(tup1, tup2):\\n  retu...   \n",
       "4  ['\\ndef ncr_modp(n, r, p):\\n    if n < r:\\n   ...   \n",
       "\n",
       "                                output_parsed_answer  \\\n",
       "0  \\ndef check_distinct(tup):\\n  return len(tup) ...   \n",
       "1  \\ndef first_non_repeating_character(s):\\n    c...   \n",
       "2  \\nimport re\\ndef check_char(s):\\n    if re.mat...   \n",
       "3  \\ndef add_nested_tuples(tup1, tup2):\\n  return...   \n",
       "4  \\ndef ncr_modp(n, r, p):\\n    if n < r:\\n     ...   \n",
       "\n",
       "   output_choice_completions  ...  \\\n",
       "0                        NaN  ...   \n",
       "1                        NaN  ...   \n",
       "2                        NaN  ...   \n",
       "3                        NaN  ...   \n",
       "4                        NaN  ...   \n",
       "\n",
       "                         trajectories_and_context_10  \\\n",
       "0   <chain_of_thoughts>\\n        <thinking>\\n    ...   \n",
       "1   <chain_of_thoughts>\\n        <thinking>\\n    ...   \n",
       "2   <chain_of_thoughts>\\n        <thinking>\\n    ...   \n",
       "3   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "4   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "\n",
       "                                context_expansion_10  \\\n",
       "0  Proposed solution context: Given a tuple, chec...   \n",
       "1  Proposed solution context: def first_non_repea...   \n",
       "2  Proposed solution context: Problem: Check if a...   \n",
       "3  Proposed solution context: Problem: Write a fu...   \n",
       "4  Proposed solution context: Problem: Calculate ...   \n",
       "\n",
       "                                     final_output_23  \\\n",
       "0  \\ndef check_distinct(numbers):\\n    \"\"\"Check i...   \n",
       "1  \\ndef first_non_repeating_character(s):\\n    c...   \n",
       "2  \\ndef check_char(s):\\n    \"\"\"Returns 'Valid' i...   \n",
       "3  \\ndef add_nested_tuples(tup1, tup2):\\n    if l...   \n",
       "4  \\nimport math\\n\\ndef ncr_modp(n, r, p):\\n    i...   \n",
       "\n",
       "                              extracted_functions_23  \\\n",
       "0  def check_distinct(numbers):\\n    return len(n...   \n",
       "1  def first_non_repeating_character(s):\\n    cha...   \n",
       "2  def check_char(s):\\n    if len(set(s)) == 1:\\n...   \n",
       "3  def add_nested_tuples(tup1, tup2):\\n    if len...   \n",
       "4  import math\\n\\ndef ncr_modp(n, r, p):\\n    if ...   \n",
       "\n",
       "                         trajectories_and_context_23  \\\n",
       "0   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "1   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "2   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "3   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "4   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "\n",
       "                                context_expansion_23  \\\n",
       "0  Proposed solution context: Problem: Write a fu...   \n",
       "1  Proposed solution context: The problem is to f...   \n",
       "2  Proposed solution context: def check_char(s):\\...   \n",
       "3  Proposed solution context: Problem: Write a fu...   \n",
       "4  Proposed solution context: Problem: Calculate ...   \n",
       "\n",
       "                                   final_output_orig  \\\n",
       "0  \\ndef check_distinct(numbers):\\n    \"\"\"\\n    C...   \n",
       "1  \\ndef first_non_repeating_character(s):\\n    \"...   \n",
       "2  \\ndef check_char(s):\\n    \"\"\"\\n    This functi...   \n",
       "3  \\ndef add_nested_tuples(tup1, tup2):\\n    \"\"\"\\...   \n",
       "4  \\ndef ncr_modp(n, r, p):\\n    if r > n - r: \\n...   \n",
       "\n",
       "                            extracted_functions_orig  \\\n",
       "0  def check_distinct(numbers):\\n    return len(n...   \n",
       "1  def first_non_repeating_character(s):\\n    cha...   \n",
       "2  def check_char(s):\\n    s = s.lower()\\n    if ...   \n",
       "3  def add_nested_tuples(tup1, tup2):\\n    return...   \n",
       "4  def ncr_modp(n, r, p):\\n    if r > n - r: \\n  ...   \n",
       "\n",
       "                       trajectories_and_context_orig  \\\n",
       "0   <chain_of_thoughts>\\n    <thinking>\\n    <top...   \n",
       "1   <chain_of_thoughts>\\n        <thinking>\\n    ...   \n",
       "2   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "3   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "4   <chain_of_thoughts>\\n    <thinking>\\n        ...   \n",
       "\n",
       "                              context_expansion_orig  \n",
       "0  Proposed solution context: Problem: Check if a...  \n",
       "1  Proposed solution context: The problem is to f...  \n",
       "2  Proposed solution context: The problem stateme...  \n",
       "3  Proposed solution context: Problem: Write a fu...  \n",
       "4  Proposed solution context: Problem: Calculate ...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cb8fd3-eacc-441a-a4f7-964d048a0066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   task_type                               250 non-null    object \n",
      " 1   task_name                               250 non-null    object \n",
      " 2   subtask_name                            0 non-null      float64\n",
      " 3   input_question                          250 non-null    object \n",
      " 4   input_choice_list                       0 non-null      float64\n",
      " 5   input_final_prompts                     250 non-null    object \n",
      " 6   input_correct_responses                 0 non-null      float64\n",
      " 7   output_prediction_text                  250 non-null    object \n",
      " 8   output_parsed_answer                    250 non-null    object \n",
      " 9   output_choice_completions               0 non-null      float64\n",
      " 10  output_choice_negative_log_likelihoods  0 non-null      float64\n",
      " 11  output_metrics                          250 non-null    object \n",
      " 12  is_correct                              250 non-null    bool   \n",
      " 13  input_question_hash                     250 non-null    object \n",
      " 14  input_final_prompts_hash                250 non-null    object \n",
      " 15  benchmark_label                         250 non-null    object \n",
      " 16  eval_config                             250 non-null    object \n",
      " 17  context                                 250 non-null    object \n",
      " 18  query                                   250 non-null    object \n",
      " 19  extracted_test_cases                    250 non-null    object \n",
      " 20  final_output_1                          169 non-null    object \n",
      " 21  extracted_functions_1                   75 non-null     object \n",
      " 22  trajectories_and_context_1              169 non-null    object \n",
      " 23  context_expansion_1                     169 non-null    object \n",
      " 24  final_output_10                         168 non-null    object \n",
      " 25  extracted_functions_10                  167 non-null    object \n",
      " 26  trajectories_and_context_10             168 non-null    object \n",
      " 27  context_expansion_10                    168 non-null    object \n",
      " 28  final_output_23                         168 non-null    object \n",
      " 29  extracted_functions_23                  168 non-null    object \n",
      " 30  trajectories_and_context_23             168 non-null    object \n",
      " 31  context_expansion_23                    168 non-null    object \n",
      " 32  final_output_orig                       168 non-null    object \n",
      " 33  extracted_functions_orig                168 non-null    object \n",
      " 34  trajectories_and_context_orig           168 non-null    object \n",
      " 35  context_expansion_orig                  168 non-null    object \n",
      "dtypes: bool(1), float64(5), object(30)\n",
      "memory usage: 68.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5b3119-8f03-45f1-94f6-ddf53a413924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['task_type', 'task_name', 'subtask_name', 'input_question',\n",
      "       'input_choice_list', 'input_final_prompts', 'input_correct_responses',\n",
      "       'output_prediction_text', 'output_parsed_answer',\n",
      "       'output_choice_completions',\n",
      "       ...\n",
      "       'comment_ratio_orig', 'h1_orig', 'h2_orig', 'N1_orig', 'N2_orig',\n",
      "       'vocabulary_orig', 'length_orig', 'volume_orig', 'difficulty_orig',\n",
      "       'effort_orig'],\n",
      "      dtype='object', length=104)\n"
     ]
    }
   ],
   "source": [
    "def code_length(func: str) -> dict:\n",
    "    lines = func.split(\"\\n\")\n",
    "    return {\"lines\": len(lines), \"characters\": len(func)}\n",
    "\n",
    "\n",
    "def comment_analysis(func: str) -> dict:\n",
    "    lines = func.split(\"\\n\")\n",
    "    comment_lines = sum(1 for line in lines if line.strip().startswith(\"#\"))\n",
    "    return {\n",
    "        \"comment_lines\": comment_lines,\n",
    "        \"comment_ratio\": comment_lines / len(lines) if lines else 0,\n",
    "    }\n",
    "\n",
    "def cyclomatic_complexity(func: str) -> int:\n",
    "    try:\n",
    "        return max((cc.complexity for cc in cc_visit(func)), default=0)\n",
    "    except:\n",
    "        return 0\n",
    "def syntactic_correctness(func: str) -> bool:\n",
    "    try:\n",
    "        ast.parse(func)\n",
    "        return True\n",
    "    except SyntaxError:\n",
    "        return False\n",
    "        \n",
    "def extract_function_name(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    pattern = r\"(?:def|class|assert)\\s+([\\w\\d_]+)\\s*\\(\"\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1) if match else None\n",
    "def check_function_name_consistency(test_cases: str, generated_function: str) -> float:\n",
    "    test_func_name = extract_function_name(test_cases)\n",
    "    generated_func_name = extract_function_name(generated_function)\n",
    "\n",
    "    if test_func_name and generated_func_name:\n",
    "        if test_func_name == generated_func_name:\n",
    "            pass\n",
    "            # print(\"yes equal: \", test_func_name, generated_func_name)\n",
    "        else:\n",
    "            if generated_function.lower().__contains__(test_func_name):\n",
    "                return float(generated_function.lower().__contains__(test_func_name))\n",
    "            # print(f\"not equal: tests; {test_func_name}\\ngens: {generated_func_name}, \\nbut is contained? {float(generated_function.lower().__contains__(test_func_name))}\")\n",
    "        \n",
    "        return float(test_func_name == generated_func_name)\n",
    "\n",
    "    if generated_function.lower().__contains__(test_func_name.lower()):\n",
    "        return float(generated_function.lower().__contains__(test_func_name))\n",
    "        # print(f\"not equal: tests; {test_func_name}\\ngens: {generated_func_name}, \\nbut is contained? {float(generated_function.lower().__contains__(test_func_name))}\")\n",
    "        \n",
    "    # print(\"were not equal: \", test_func_name, generated_func_name)\n",
    "    return 0.0\n",
    "    \n",
    "def calculate_metrics(row: pd.Series, layer_idx: str) -> dict:\n",
    "    # func = row[f\"extracted_functions_{layer_idx}\"]\n",
    "    func = row[f\"final_output_{layer_idx}\"]\n",
    "    func = row[f\"final_output_{layer_idx}\"]\n",
    "    # if func:\n",
    "        # print(\"func: \", func)\n",
    "        # print(\"func: \", row[\"extracted_test_cases\"])\n",
    "        # print(\"=\" * 100)\n",
    "    if pd.isna(func):\n",
    "        return {\n",
    "            f\"{metric}_{layer_idx}\": np.nan\n",
    "            for metric in [\n",
    "                \"syntactic_correctness\",\n",
    "                \"cyclomatic_complexity\",\n",
    "                \"function_name_consistency\",\n",
    "                \"lines\",\n",
    "                \"characters\",\n",
    "                \"comment_lines\",\n",
    "                \"comment_ratio\",\n",
    "                \"h1\",\n",
    "                \"h2\",\n",
    "                \"N1\",\n",
    "                \"N2\",\n",
    "                \"vocabulary\",\n",
    "                \"length\",\n",
    "                \"volume\",\n",
    "                \"difficulty\",\n",
    "                \"effort\",\n",
    "            ]\n",
    "        }\n",
    "    # print(\n",
    "    #     f\"for layer idx {layer_idx}: \",\n",
    "    #     check_function_name_consistency(row[\"extracted_test_cases\"], func),\n",
    "    # )\n",
    "    metrics = {\n",
    "        f\"syntactic_correctness_{layer_idx}\": int(syntactic_correctness(func)),\n",
    "        f\"cyclomatic_complexity_{layer_idx}\": cyclomatic_complexity(func),\n",
    "        f\"function_name_consistency_{layer_idx}\": check_function_name_consistency(\n",
    "            row[\"extracted_test_cases\"], func\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    length_metrics = code_length(func)\n",
    "    metrics.update({f\"{k}_{layer_idx}\": v for k, v in length_metrics.items()})\n",
    "\n",
    "    comment_metrics = comment_analysis(func)\n",
    "    metrics.update({f\"{k}_{layer_idx}\": v for k, v in comment_metrics.items()})\n",
    "\n",
    "    try:\n",
    "        h_metrics = h_visit(func)\n",
    "        metrics.update({f\"{k}_{layer_idx}\": v for k, v in h_metrics.items()})\n",
    "    except:\n",
    "        metrics.update(\n",
    "            {\n",
    "                f\"{k}_{layer_idx}\": np.nan\n",
    "                for k in [\n",
    "                    \"h1\",\n",
    "                    \"h2\",\n",
    "                    \"N1\",\n",
    "                    \"N2\",\n",
    "                    \"vocabulary\",\n",
    "                    \"length\",\n",
    "                    \"volume\",\n",
    "                    \"difficulty\",\n",
    "                    \"effort\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    new_df = df.copy()\n",
    "\n",
    "    for layer_idx in [\"1\", \"10\", \"23\", \"orig\"]:\n",
    "        new_df[f\"response_rate_{layer_idx}\"] = (\n",
    "            new_df[f\"extracted_functions_{layer_idx}\"].notna().astype(int)\n",
    "        )\n",
    "\n",
    "        metrics = new_df.apply(lambda row: calculate_metrics(row, layer_idx), axis=1)\n",
    "        # metrics = pd.DataFrame(\n",
    "        #     [calculate_metrics(row, layer_idx) for _, row in new_df.iterrows()]\n",
    "        # )\n",
    "        for metric in metrics.iloc[0].keys():\n",
    "            new_df[metric] = metrics.apply(lambda x: x[metric])\n",
    "\n",
    "    return new_df\n",
    "new_df = process_dataframe(df)\n",
    "print(str(new_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7d2da3-86ff-48bb-b1ee-705a5e213ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 104 columns):\n",
      " #    Column                                  Non-Null Count  Dtype  \n",
      "---   ------                                  --------------  -----  \n",
      " 0    task_type                               250 non-null    object \n",
      " 1    task_name                               250 non-null    object \n",
      " 2    subtask_name                            0 non-null      float64\n",
      " 3    input_question                          250 non-null    object \n",
      " 4    input_choice_list                       0 non-null      float64\n",
      " 5    input_final_prompts                     250 non-null    object \n",
      " 6    input_correct_responses                 0 non-null      float64\n",
      " 7    output_prediction_text                  250 non-null    object \n",
      " 8    output_parsed_answer                    250 non-null    object \n",
      " 9    output_choice_completions               0 non-null      float64\n",
      " 10   output_choice_negative_log_likelihoods  0 non-null      float64\n",
      " 11   output_metrics                          250 non-null    object \n",
      " 12   is_correct                              250 non-null    bool   \n",
      " 13   input_question_hash                     250 non-null    object \n",
      " 14   input_final_prompts_hash                250 non-null    object \n",
      " 15   benchmark_label                         250 non-null    object \n",
      " 16   eval_config                             250 non-null    object \n",
      " 17   context                                 250 non-null    object \n",
      " 18   query                                   250 non-null    object \n",
      " 19   extracted_test_cases                    250 non-null    object \n",
      " 20   final_output_1                          169 non-null    object \n",
      " 21   extracted_functions_1                   75 non-null     object \n",
      " 22   trajectories_and_context_1              169 non-null    object \n",
      " 23   context_expansion_1                     169 non-null    object \n",
      " 24   final_output_10                         168 non-null    object \n",
      " 25   extracted_functions_10                  167 non-null    object \n",
      " 26   trajectories_and_context_10             168 non-null    object \n",
      " 27   context_expansion_10                    168 non-null    object \n",
      " 28   final_output_23                         168 non-null    object \n",
      " 29   extracted_functions_23                  168 non-null    object \n",
      " 30   trajectories_and_context_23             168 non-null    object \n",
      " 31   context_expansion_23                    168 non-null    object \n",
      " 32   final_output_orig                       168 non-null    object \n",
      " 33   extracted_functions_orig                168 non-null    object \n",
      " 34   trajectories_and_context_orig           168 non-null    object \n",
      " 35   context_expansion_orig                  168 non-null    object \n",
      " 36   response_rate_1                         250 non-null    int64  \n",
      " 37   syntactic_correctness_1                 169 non-null    float64\n",
      " 38   cyclomatic_complexity_1                 169 non-null    float64\n",
      " 39   function_name_consistency_1             169 non-null    float64\n",
      " 40   lines_1                                 169 non-null    float64\n",
      " 41   characters_1                            169 non-null    float64\n",
      " 42   comment_lines_1                         169 non-null    float64\n",
      " 43   comment_ratio_1                         169 non-null    float64\n",
      " 44   h1_1                                    0 non-null      float64\n",
      " 45   h2_1                                    0 non-null      float64\n",
      " 46   N1_1                                    0 non-null      float64\n",
      " 47   N2_1                                    0 non-null      float64\n",
      " 48   vocabulary_1                            0 non-null      float64\n",
      " 49   length_1                                0 non-null      float64\n",
      " 50   volume_1                                0 non-null      float64\n",
      " 51   difficulty_1                            0 non-null      float64\n",
      " 52   effort_1                                0 non-null      float64\n",
      " 53   response_rate_10                        250 non-null    int64  \n",
      " 54   syntactic_correctness_10                168 non-null    float64\n",
      " 55   cyclomatic_complexity_10                168 non-null    float64\n",
      " 56   function_name_consistency_10            168 non-null    float64\n",
      " 57   lines_10                                168 non-null    float64\n",
      " 58   characters_10                           168 non-null    float64\n",
      " 59   comment_lines_10                        168 non-null    float64\n",
      " 60   comment_ratio_10                        168 non-null    float64\n",
      " 61   h1_10                                   0 non-null      float64\n",
      " 62   h2_10                                   0 non-null      float64\n",
      " 63   N1_10                                   0 non-null      float64\n",
      " 64   N2_10                                   0 non-null      float64\n",
      " 65   vocabulary_10                           0 non-null      float64\n",
      " 66   length_10                               0 non-null      float64\n",
      " 67   volume_10                               0 non-null      float64\n",
      " 68   difficulty_10                           0 non-null      float64\n",
      " 69   effort_10                               0 non-null      float64\n",
      " 70   response_rate_23                        250 non-null    int64  \n",
      " 71   syntactic_correctness_23                168 non-null    float64\n",
      " 72   cyclomatic_complexity_23                168 non-null    float64\n",
      " 73   function_name_consistency_23            168 non-null    float64\n",
      " 74   lines_23                                168 non-null    float64\n",
      " 75   characters_23                           168 non-null    float64\n",
      " 76   comment_lines_23                        168 non-null    float64\n",
      " 77   comment_ratio_23                        168 non-null    float64\n",
      " 78   h1_23                                   0 non-null      float64\n",
      " 79   h2_23                                   0 non-null      float64\n",
      " 80   N1_23                                   0 non-null      float64\n",
      " 81   N2_23                                   0 non-null      float64\n",
      " 82   vocabulary_23                           0 non-null      float64\n",
      " 83   length_23                               0 non-null      float64\n",
      " 84   volume_23                               0 non-null      float64\n",
      " 85   difficulty_23                           0 non-null      float64\n",
      " 86   effort_23                               0 non-null      float64\n",
      " 87   response_rate_orig                      250 non-null    int64  \n",
      " 88   syntactic_correctness_orig              168 non-null    float64\n",
      " 89   cyclomatic_complexity_orig              168 non-null    float64\n",
      " 90   function_name_consistency_orig          168 non-null    float64\n",
      " 91   lines_orig                              168 non-null    float64\n",
      " 92   characters_orig                         168 non-null    float64\n",
      " 93   comment_lines_orig                      168 non-null    float64\n",
      " 94   comment_ratio_orig                      168 non-null    float64\n",
      " 95   h1_orig                                 0 non-null      float64\n",
      " 96   h2_orig                                 0 non-null      float64\n",
      " 97   N1_orig                                 0 non-null      float64\n",
      " 98   N2_orig                                 0 non-null      float64\n",
      " 99   vocabulary_orig                         0 non-null      float64\n",
      " 100  length_orig                             0 non-null      float64\n",
      " 101  volume_orig                             0 non-null      float64\n",
      " 102  difficulty_orig                         0 non-null      float64\n",
      " 103  effort_orig                             0 non-null      float64\n",
      "dtypes: bool(1), float64(69), int64(4), object(30)\n",
      "memory usage: 201.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"structured_checkpoint_data.csv\")\n",
    "# dfnew = pd.read_csv(\"codellm_metrics.csv\")\n",
    "\n",
    "# Save the new DataFrame\n",
    "new_df.to_csv(\"codellm_metrics_notebook_v.csv\", index=False)\n",
    "print(new_df.info(max_cols=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27b163dc-045d-4e9c-a6ae-92fa4c04e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with comments extraction ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\}'\n",
      "/tmp/ipykernel_1040796/2222861860.py:10: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  function_pattern = '# MODE:\\n(.*?)\\}'\n",
      "/tmp/ipykernel_1040796/2222861860.py:10: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  function_pattern = '# MODE:\\n(.*?)\\}'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(processed_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpure_code_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_with_comments_1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_code_extraction\u001b[39m(df, num_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[47], line 107\u001b[0m, in \u001b[0;36mprocess_dataframe\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m new_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# print(\"pure extraction ..\")\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# new_df[f'pure_code_{layer_idx}'] = new_df[column_name].apply(extract_pure_python_code)\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith comments extraction ..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m         new_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_with_comments_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_pure_python_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n",
      "File \u001b[0;32m~/PycharmProjects/moc/venv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/moc/venv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/moc/venv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/PycharmProjects/moc/venv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/moc/venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[47], line 39\u001b[0m, in \u001b[0;36mextract_pure_python_code\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_pure_python_code\u001b[39m(text):\n\u001b[0;32m---> 39\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m     functions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m     current_function \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "def extract_pure_python_code(text):\n",
    "    # Extract imports\n",
    "    import_pattern = r\"^(?:from\\s+[\\w.]+\\s+import\\s+(?:[\\w.]+(?:\\s*,\\s*[\\w.]+)*|\\*)|import\\s+(?:[\\w.]+(?:\\s*,\\s*[\\w.]+)*))(?:\\s+as\\s+[\\w.]+)?\"\n",
    "    imports = re.findall(import_pattern, text, re.MULTILINE)\n",
    "\n",
    "    # Extract functions\n",
    "    function_pattern = r\"(def\\s+\\w+\\s*\\(.*?\\):(?:\\s*['\\\"][\\s\\S]*?['\\\"])?\\s*(?:(?!def\\s)[\\s\\S])*?(?=\\ndef|\\Z))\"\n",
    "    function_pattern = r\"(def\\s+\\w+\\s*\\([^)]*\\):\\s*(?:(?:'''[\\s\\S]*?'''|\\\"\\\"\\\"[\\s\\S]*?\\\"\\\"\\\")?\\s*[\\s\\S]*?)(?=\\ndef|\\Z))\"\n",
    "    function_pattern = r\"(def\\s+\\w+\\s*\\([^)]*\\):(?:\\s*(?:\\\"\\\"\\\"[\\s\\S]*?\\\"\\\"\\\"|'''.*?''')?\\s*)?[\\s\\S]*?(?=\\ndef\\s|\\Z))\"\n",
    "    function_pattern = '# MODE:\\n(.*?)\\}'\n",
    "    # function_pattern = r\"def\\s+\\w+\\s*\\([^)]*\\):\\s*(?:(?:'''[\\s\\S]*?'''|\\\"\\\"\\\"[\\s\\S]*?\\\"\\\"\\\")?\\s*[\\s\\S]*?(?=\\ndef|\\Z))\"\n",
    "\n",
    "    functions = re.findall(function_pattern, text, re.MULTILINE | re.DOTALL)\n",
    "\n",
    "    def clean_code(code):\n",
    "        # Remove docstrings\n",
    "        # code = re.sub(r'\"\"\"[\\\\s\\\\S]*?\"\"\"|\\'\\'\\'[\\\\\\s\\\\S]*?\\'\\'\\'|\\'''[\\\\s\\\\S]*?\\'''', \"\", code)\n",
    "        code = re.sub(r'\"\"\"[\\\\s\\\\S]*?\"\"\"|\\'\\'\\'[\\\\s\\\\S]*?\\'\\'\\'', \"\", code)\n",
    "\n",
    "        # Remove comments\n",
    "        code = re.sub(r\"#.*\", \"\", code)\n",
    "        # Remove empty lines and trailing whitespace\n",
    "        code = \"\\n\".join(line for line in code.splitlines() if line.strip())\n",
    "        return code\n",
    "\n",
    "    cleaned_imports = [clean_code(imp) for imp in imports]\n",
    "    cleaned_functions = [clean_code(func) for func in functions]\n",
    "\n",
    "    # Combine imports and functions\n",
    "    cleaned_code = \"\\n\".join(cleaned_imports)\n",
    "    if cleaned_imports and cleaned_functions:\n",
    "        cleaned_code += \"\\n\\n\"\n",
    "    cleaned_code += \"\\n\\n\".join(cleaned_functions)\n",
    "\n",
    "    return cleaned_code\n",
    "\n",
    "def extract_pure_python_code(text):\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    functions = []\n",
    "    current_function = []\n",
    "    indent_level = 0\n",
    "    in_function = False\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        \n",
    "        # Check for function or class definition\n",
    "        if re.match(r'^(def|class)\\s', stripped_line):\n",
    "            if in_function:\n",
    "                # Save the previous function if we're starting a new one\n",
    "                functions.append('\\n'.join(current_function))\n",
    "                current_function = []\n",
    "            in_function = True\n",
    "            indent_level = len(line) - len(line.lstrip())\n",
    "            current_function.append(line)\n",
    "        elif in_function:\n",
    "            # Check if this line is part of the current function\n",
    "            if line.strip() == '' or len(line) - len(line.lstrip()) > indent_level:\n",
    "                current_function.append(line)\n",
    "            else:\n",
    "                # This line is not part of the function, so the function has ended\n",
    "                functions.append('\\n'.join(current_function))\n",
    "                current_function = []\n",
    "                in_function = False\n",
    "                if re.match(r'^(def|class)\\s', stripped_line):\n",
    "                    # If this is a new function definition, start a new function\n",
    "                    in_function = True\n",
    "                    indent_level = len(line) - len(line.lstrip())\n",
    "                    current_function.append(line)\n",
    "\n",
    "    # Add the last function if there is one\n",
    "    if current_function:\n",
    "        functions.append('\\n'.join(current_function))\n",
    "\n",
    "    return functions\n",
    "\n",
    "def extract_python_code_with_comments(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    # Regex pattern to match Python code blocks\n",
    "    pattern = r'```(?:python)?\\s*\\n((?:(?!```).|\\n)+)\\s*```'\n",
    "    matches = re.findall(pattern, text, re.MULTILINE | re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        print(\"not matches with comments\")\n",
    "        # Fallback pattern for code not wrapped in backticks\n",
    "        pattern = r'(?:^|\\n)((?:import\\s+\\w+|from\\s+\\w+\\s+import\\s+[\\w,\\s]+|def\\s+\\w+\\s*\\(|class\\s+\\w+[^\\n]*:)(?:\\n(?!```|import\\s+\\w+|from\\s+\\w+\\s+import|def\\s+\\w+\\s*\\(|class\\s+\\w+).*)*)'\n",
    "        matches = re.findall(pattern, text, re.MULTILINE)\n",
    "    \n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    return '\\n\\n'.join(matches)\n",
    "\n",
    "def process_dataframe(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    layer_indices = ['1', '10', '23', 'orig']\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        column_name = f'final_output_{layer_idx}'\n",
    "        if column_name in new_df.columns:\n",
    "            # print(\"pure extraction ..\")\n",
    "            # new_df[f'pure_code_{layer_idx}'] = new_df[column_name].apply(extract_pure_python_code)\n",
    "            print(\"with comments extraction ..\")\n",
    "            new_df[f'code_with_comments_{layer_idx}'] = new_df[column_name].apply(extract_pure_python_code)\n",
    "    \n",
    "    return new_df\n",
    "# \n",
    "processed_df = process_dataframe(new_df)\n",
    "print(processed_df[['pure_code_1', 'code_with_comments_1']].head())\n",
    "\n",
    "def test_code_extraction(df, num_rows=3):\n",
    "    layer_indices = ['1', '10', '23', 'orig']\n",
    "    \n",
    "    for i in range(min(num_rows, len(df))):\n",
    "        print(f\"\\nRow {i + 1}:\")\n",
    "        for layer_idx in layer_indices:\n",
    "            column_name = f'final_output_{layer_idx}'\n",
    "            if column_name in df.columns:\n",
    "                text = df.loc[i, column_name]\n",
    "                if pd.notna(text):\n",
    "                    extracted_code = extract_pure_python_code(text)\n",
    "                    print(f\"\\nLayer {layer_idx}:\")\n",
    "                    print(len(extracted_code) if extracted_code else f\"No code extracted: {text}\")\n",
    "                    if extracted_code:\n",
    "                        for code in extracted_code:\n",
    "                            print(code)\n",
    "                else:\n",
    "                    print(f\"\\nLayer {layer_idx}: NaN value\")\n",
    "            else:\n",
    "                print(f\"\\nLayer {layer_idx}: Column not found\")\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Assuming 'new_df' is your DataFrame\n",
    "# Test the function on the first 3 rows\n",
    "# test_code_extraction(new_df)\n",
    "processed_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0de682cb-f151-424e-973f-43710139c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Columns: 104 entries, task_type to effort_orig\n",
      "dtypes: bool(1), float64(69), int64(4), object(30)\n",
      "memory usage: 201.5+ KB\n",
      "None\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Response Rates Across Different Layers}\n",
      "\\label{tab:response_rates}\n",
      "\\begin{tabular}{lcccc}\n",
      "\\hline\n",
      "Metric & Layer 1 & Layer 10 & Layer 23 & Original \\\\\n",
      "\\hline\n",
      "Response Rate & 0.3000 & 0.6680 & 0.6720 & 0.6720 \\\\\n",
      "Sample Size & 169.0000 & 169.0000 & 169.0000 & 169.0000 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Code Quality Metrics Across Different Layers}\n",
      "\\label{tab:code_quality}\n",
      "\\begin{tabular}{lcccc}\n",
      "\\hline\n",
      "Metric & Layer 1 & Layer 10 & Layer 23 & Original \\\\\n",
      "\\hline\n",
      "Syntactic Correctness & 0.0059 & 0.0357 & 0.0179 & 0.1190 \\\\\n",
      "Function Name Consistency & 0.6568 & 1.0000 & 0.9821 & 0.9940 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Code Complexity Metrics Across Different Layers}\n",
      "\\label{tab:code_complexity}\n",
      "\\begin{tabular}{lcccc}\n",
      "\\hline\n",
      "Metric & Layer 1 & Layer 10 & Layer 23 & Original \\\\\n",
      "\\hline\n",
      "Cyclomatic Complexity & 0.0000 & 0.1190 & 0.0833 & 0.4167 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Code Structure Metrics Across Different Layers}\n",
      "\\label{tab:code_structure}\n",
      "\\begin{tabular}{lcccc}\n",
      "\\hline\n",
      "Metric & Layer 1 & Layer 10 & Layer 23 & Original \\\\\n",
      "\\hline\n",
      "Lines of Code & 14.8994 & 21.8274 & 12.6429 & 24.8095 \\\\\n",
      "Characters & 568.2130 & 706.6667 & 431.0119 & 811.8810 \\\\\n",
      "Comment Lines & 0.6036 & 1.8274 & 0.6012 & 3.3750 \\\\\n",
      "Comment Ratio & 0.0316 & 0.0809 & 0.0343 & 0.1202 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame\n",
    "metrics_df = pd.read_csv(\"codellm_metrics_notebook_v.csv\")\n",
    "print(metrics_df.info())\n",
    "gen_list_len = 169\n",
    "\n",
    "def generate_latex_table(data, caption, label):\n",
    "    latex = f\"\\\\begin{{table}}[h]\\n\\\\centering\\n\\\\caption{{{caption}}}\\n\\\\label{{{label}}}\\n\"\n",
    "    latex += \"\\\\begin{tabular}{l\" + \"c\" * len(data.columns) + \"}\\n\\\\hline\\n\"\n",
    "    latex += \"Metric & \" + \" & \".join(data.columns) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "    for index, row in data.iterrows():\n",
    "        latex += (\n",
    "            f\"{index} & \"\n",
    "            + \" & \".join([f\"{x:.4f}\" if isinstance(x, float) else str(x) for x in row])\n",
    "            + \" \\\\\\\\\\n\"\n",
    "        )\n",
    "    latex += \"\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "    return latex\n",
    "\n",
    "\n",
    "# Response Rates\n",
    "response_rates = metrics_df[[f\"response_rate_{i}\" for i in [\"1\", \"10\", \"23\", \"orig\"]]].mean()\n",
    "response_rates_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer 1\": [response_rates[\"response_rate_1\"], gen_list_len],\n",
    "        \"Layer 10\": [response_rates[\"response_rate_10\"], gen_list_len],\n",
    "        \"Layer 23\": [response_rates[\"response_rate_23\"], gen_list_len],\n",
    "        \"Original\": [response_rates[\"response_rate_orig\"], gen_list_len],\n",
    "    },\n",
    "    index=[\"Response Rate\", \"Sample Size\"],\n",
    ")\n",
    "response_rates_latex = generate_latex_table(\n",
    "    response_rates_data, \"Response Rates Across Different Layers\", \"tab:response_rates\"\n",
    ")\n",
    "\n",
    "# Code Quality Metrics\n",
    "code_quality_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer 1\": [\n",
    "            metrics_df[\"syntactic_correctness_1\"].mean(),\n",
    "            metrics_df[\"function_name_consistency_1\"].mean(),\n",
    "        ],\n",
    "        \"Layer 10\": [\n",
    "            metrics_df[\"syntactic_correctness_10\"].mean(),\n",
    "            metrics_df[\"function_name_consistency_10\"].mean(),\n",
    "        ],\n",
    "        \"Layer 23\": [\n",
    "            metrics_df[\"syntactic_correctness_23\"].mean(),\n",
    "            metrics_df[\"function_name_consistency_23\"].mean(),\n",
    "        ],\n",
    "        \"Original\": [\n",
    "            metrics_df[\"syntactic_correctness_orig\"].mean(),\n",
    "            metrics_df[\"function_name_consistency_orig\"].mean(),\n",
    "        ],\n",
    "    },\n",
    "    index=[\"Syntactic Correctness\", \"Function Name Consistency\"],\n",
    ")\n",
    "code_quality_latex = generate_latex_table(\n",
    "    code_quality_data,\n",
    "    \"Code Quality Metrics Across Different Layers\",\n",
    "    \"tab:code_quality\",\n",
    ")\n",
    "\n",
    "# Code Complexity Metrics\n",
    "code_complexity_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer 1\": [metrics_df[\"cyclomatic_complexity_1\"].mean()],\n",
    "        \"Layer 10\": [metrics_df[\"cyclomatic_complexity_10\"].mean()],\n",
    "        \"Layer 23\": [metrics_df[\"cyclomatic_complexity_23\"].mean()],\n",
    "        \"Original\": [metrics_df[\"cyclomatic_complexity_orig\"].mean()],\n",
    "    },\n",
    "    index=[\"Cyclomatic Complexity\"],\n",
    ")\n",
    "code_complexity_latex = generate_latex_table(\n",
    "    code_complexity_data,\n",
    "    \"Code Complexity Metrics Across Different Layers\",\n",
    "    \"tab:code_complexity\",\n",
    ")\n",
    "\n",
    "# Code Structure Metrics\n",
    "code_structure_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer 1\": [\n",
    "            metrics_df[\"lines_1\"].mean(),\n",
    "            metrics_df[\"characters_1\"].mean(),\n",
    "            metrics_df[\"comment_lines_1\"].mean(),\n",
    "            metrics_df[\"comment_ratio_1\"].mean(),\n",
    "        ],\n",
    "        \"Layer 10\": [\n",
    "            metrics_df[\"lines_10\"].mean(),\n",
    "            metrics_df[\"characters_10\"].mean(),\n",
    "            metrics_df[\"comment_lines_10\"].mean(),\n",
    "            metrics_df[\"comment_ratio_10\"].mean(),\n",
    "        ],\n",
    "        \"Layer 23\": [\n",
    "            metrics_df[\"lines_23\"].mean(),\n",
    "            metrics_df[\"characters_23\"].mean(),\n",
    "            metrics_df[\"comment_lines_23\"].mean(),\n",
    "            metrics_df[\"comment_ratio_23\"].mean(),\n",
    "        ],\n",
    "        \"Original\": [\n",
    "            metrics_df[\"lines_orig\"].mean(),\n",
    "            metrics_df[\"characters_orig\"].mean(),\n",
    "            metrics_df[\"comment_lines_orig\"].mean(),\n",
    "            metrics_df[\"comment_ratio_orig\"].mean(),\n",
    "        ],\n",
    "    },\n",
    "    index=[\"Lines of Code\", \"Characters\", \"Comment Lines\", \"Comment Ratio\"],\n",
    ")\n",
    "code_structure_latex = generate_latex_table(\n",
    "    code_structure_data,\n",
    "    \"Code Structure Metrics Across Different Layers\",\n",
    "    \"tab:code_structure\",\n",
    ")\n",
    "\n",
    "# Print LaTeX code for all tables\n",
    "print(response_rates_latex)\n",
    "print(code_quality_latex)\n",
    "print(code_complexity_latex)\n",
    "print(code_structure_latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3413a-f6c8-47d7-8566-20827c738f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
